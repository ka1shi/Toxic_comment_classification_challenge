{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic_comment_testing_v2_git.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ka1shi/Toxic_comment_classification_challenge/blob/master/Toxic_comment_testing_v2_git.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XY0isJS-0u7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GRU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXwKTPaFeaI7",
        "colab_type": "code",
        "outputId": "a1e8868c-9b08-4aac-bd85-8b03b18c3091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjuZHBlwdg5-",
        "colab_type": "code",
        "outputId": "b4fc6a29-6c1d-4895-9b8c-412d55458685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "import os\n",
        "from keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "\n",
        "from keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
        "from keras.preprocessing import text, sequence\n",
        "\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        " \n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry_sR4_Se5C1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(filename):\n",
        "    \"\"\"\n",
        "    \n",
        "    Load dataset\n",
        "    \n",
        "    Input:\n",
        "    filename : CSV file that contains data\n",
        "    \n",
        "    Output:\n",
        "    data : Data in pandas dataframe\n",
        "    \"\"\"\n",
        "    \n",
        "    #data = pd.read_csv(filename, sep='\\t')\n",
        "    data = pd.read_csv(filename, encoding = \"ISO-8859-1\")\n",
        "    #data = pd.read_csv(filename, sep='\\t', encoding = \"ISO-8859-1\", low_memory=False) \n",
        "    \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wejGJ7FfAlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename1 = '/content/drive/My Drive/jigsaw-toxic-comment-classification-challenge/train1.csv'\n",
        "filename2 = '/content/drive/My Drive/jigsaw-toxic-comment-classification-challenge/test1.csv'\n",
        "\n",
        "train = load_data(filename1)\n",
        "test = load_data(filename2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_tNH5gKSGRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILE = '/content/drive/My Drive/glove.6B/glove.6B.300d.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rti5GD3faIr",
        "colab_type": "code",
        "outputId": "0efb0210-ca7b-453d-fd16-9c5b822aea2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "train.apply(lambda x: sum(x.isnull()), axis=0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id               0\n",
              "comment_text     0\n",
              "toxic            0\n",
              "severe_toxic     0\n",
              "obscene          0\n",
              "threat           0\n",
              "insult           0\n",
              "identity_hate    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZaoRvs9fZ8-",
        "colab_type": "code",
        "outputId": "ce32c8df-f7ce-485f-8a33-38e8bf993720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "test.apply(lambda x: sum(x.isnull()), axis=0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id              0\n",
              "comment_text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwd2DZRp8tPy",
        "colab_type": "code",
        "outputId": "462d3b87-7e55-44af-adf4-1cabfabc1fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text\n",
              "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
              "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
              "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
              "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
              "4  00017695ad8997eb          I don't anonymously edit articles at all."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFGGLzCed2wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train[\"comment_text\"].str.lower()\n",
        "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
        "\n",
        "X_test = test[\"comment_text\"].str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2hbLZ1-d5bA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features=100000\n",
        "maxlen=150\n",
        "embed_size=300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M68NXhKd9Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok=text.Tokenizer(num_words=max_features,lower=True)\n",
        "tok.fit_on_texts(list(X_train)+list(X_test))\n",
        "X_train=tok.texts_to_sequences(X_train)\n",
        "X_test=tok.texts_to_sequences(X_test)\n",
        "x_train=sequence.pad_sequences(X_train,maxlen=maxlen)\n",
        "x_test=sequence.pad_sequences(X_test,maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiGmr_b8d9Yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = {}\n",
        "with open(EMBEDDING_FILE,encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.rstrip().rsplit(' ')\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mbU4azqd9bH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tok.word_index\n",
        "#prepare embedding matrix\n",
        "num_words = min(max_features, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxDmRVxAd9ef",
        "colab_type": "code",
        "outputId": "24f72fd8-b9c9-4862-86a7-5c799cb15e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "\n",
        "sequence_input = Input(shape=(maxlen, ))\n",
        "x = Embedding(max_features, embed_size, weights=[embedding_matrix],trainable = False)(sequence_input)\n",
        "x = SpatialDropout1D(0.2)(x)\n",
        "x = Bidirectional(GRU(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
        "x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
        "avg_pool = GlobalAveragePooling1D()(x)\n",
        "max_pool = GlobalMaxPooling1D()(x)\n",
        "x = concatenate([avg_pool, max_pool]) \n",
        "preds = Dense(6, activation=\"sigmoid\")(x)\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-3),metrics=['accuracy'])\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\nmodel = Sequential()\\nmodel.add(Embedding(max_features, embed_size ,weights = [embedding_matrix], input_length = maxlen, trainable = False))\\nmodel.add(SpatialDropout1D(0.2))\\nmodel.add(Bidirectional(GRU(128, return_sequence = True, dropout = 0.1, recurrent_dropout = 0.1)))\\nmodel.add(Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\"))\\navg_pool = GlobalAveragePooling1D()\\nmax_pool = GlobalMaxPooling1D()\\nconcatenated = concatenate([avg_pool, max_pool])\\n  \\nmodel.add(concatenated)\\nmodel.add(Dense(units=6))\\nmodel.add(Activation(\"sigmoid\"))\\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\\'accuracy\\'])\\n  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0qGOY1U_8e0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "f8e3e047-889d-4d48-8a28-2362127cb2c9"
      },
      "source": [
        "print (model.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 150, 300)     30000000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_1 (SpatialDro (None, 150, 300)     0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 150, 256)     329472      spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 148, 64)      49216       bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 64)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 64)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 128)          0           global_average_pooling1d_1[0][0] \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 6)            774         concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 30,379,462\n",
            "Trainable params: 379,462\n",
            "Non-trainable params: 30,000,000\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQSSA3oueJGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 4\n",
        "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.9, random_state=233)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEXmjaR1eNOY",
        "colab_type": "code",
        "outputId": "676f6426-3490-478a-f9f9-2247575c7f1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),verbose=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/4\n",
            "143613/143613 [==============================] - 1709s 12ms/step - loss: 0.0625 - acc: 0.9786 - val_loss: 0.0500 - val_acc: 0.9819\n",
            "Epoch 2/4\n",
            "143613/143613 [==============================] - 1725s 12ms/step - loss: 0.0484 - acc: 0.9822 - val_loss: 0.0483 - val_acc: 0.9826\n",
            "Epoch 3/4\n",
            "143613/143613 [==============================] - 1726s 12ms/step - loss: 0.0447 - acc: 0.9832 - val_loss: 0.0459 - val_acc: 0.9830\n",
            "Epoch 4/4\n",
            "143613/143613 [==============================] - 1717s 12ms/step - loss: 0.0419 - acc: 0.9842 - val_loss: 0.0467 - val_acc: 0.9829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ca3b23da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w-DAaLBHOiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e8fac50-9c1f-4961-8704-cbf4ef139b2c"
      },
      "source": [
        "y_pred = model.predict(x_test,batch_size=1024,verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 590s 4ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c06GIU4_eNRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.read_csv('/content/drive/My Drive/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')\n",
        "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n",
        "submission.to_csv('submission_G.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjWtrxc8eNUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('Toxic_comment_testing_v2_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf1MdIxHCZjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Toxic_comment_testing_v2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}